name: Run scraper hourly

# Schedule: runs at the start of every hour
# workflow_dispatch allows manual trigger
on:
  schedule:
    - cron: '0 * * * *'  
  workflow_dispatch:  

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout your repository
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Setup Python
      - name: Set up Python 3.13
        uses: actions/setup-python@v5
        with:
          python-version: 3.13

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Step 4: Run the scraper
      - name: Run scraper.py
        run: |
          python scraper.py

      # Step 5: Commit & push updated data.json
      - name: Commit and push updated data.json
        run: |
          git config --global user.name "cozylatte"
          git config --global user.email "aarushic.official@gmail.com"
          git add data/data.json
          git commit -m "Update data.json from scraper" || echo "No changes to commit"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
